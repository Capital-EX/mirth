
import base/panic
import base/int
import base/nat
import base/pos
import base/char
import base/order
import base/list
import base/str
import base/regex+
import base/maybe
import base/result
import mirth/types/mod
import mirth/loc
import mirth/token

export mirth/lexer
  type LToken
  type LexerError
  type Result(a,b)
  lexerError->str : LexerError -- Str
  tokenize : Mod Str -- Result(LexerError, List(LToken))
end


#
# auxiliary lexing functions
#

digitVal : Char -- Int
digitVal =
  cond(
    isdigit? -> char->int "0" str->char char->int z-,
    islower? -> char->int "a" str->char char->int z- 10 z+,
    isupper? -> char->int "A" str->char char->int z- 10 z+,
    drop 0
  )

hassign? : Str -- Str Bool
hassign? = dup n1 strtakeL cond(
  dup "-" streq -> drop true,
  dup "+" streq -> drop true,
  drop false
)
hassign? drop == id

readInt(base: Int) : Str -- Int
readInt(base) =
  hassign? if(
    n1 strbreak readInt(base)
    swap "-" streq if(zneg, id),
    dip(0) strfold(dip(base z*) digitVal z+)
  )

readDecInt : Str -- Int
readHexInt : Str -- Int
readDecInt = readInt(10)
readHexInt = n2 strdropL readInt(16)

int->str readDecInt == id

wordToken : Str -- Token  # basically TNAME but separates out reserved words.
wordToken =
  cond(
    dup "="      streq -> drop TEQUAL,
    dup "=="     streq -> drop TEQUAL2,
    dup "--"     streq -> drop TDASH2,
    dup "import" streq -> drop TIMPORT,
    dup "export" streq -> drop TEXPORT,
    dup "type"   streq -> drop TTYPE,
    dup "data"   streq -> drop TDATA,
    dup "end"    streq -> drop TEND,
    TNAME
  )

isEscapeChar? : Char -- Char Bool
isEscapeChar? = dup "\\" str->char chareq

interpretEscapedChar : Char -- Char
interpretEscapedChar =
  cond(
    dup "n" str->char chareq -> drop "\n" str->char,
    dup "r" str->char chareq -> drop "\r" str->char,
    dup "t" str->char chareq -> drop "\t" str->char,
    id
  )


readStringBody : Str -- Str
readStringBody = dip("" false) strfold(
  swap if(
    cond(
      isEscapeChar? -> drop true,
      char->str <> false
    ),
    interpretEscapedChar char->str <> false
  )
) drop

readString : Str -- Str
readString = n1 strdropL n1 strdropR readStringBody

readMultistring : Str -- Str
readMultistring = 3 znat strdropL 3 znat strdropR readStringBody

#
# regexes
#

decIntRegex : Regex
decIntRegex = "" lit "+-" cls alt2 "0123456789" cls plus seq2

hexIntRegex : Regex
hexIntRegex = "" lit "+-" cls alt2 "0" lit "xX" cls "0123456789abcdefABCDEF" cls plus seq4

wordRegex : Regex
wordRegex = "0123456789abcdefghijklmnopqrstuvwxyzzABCDEFGHIJKLMNOPQRSTUVWXYZ_-?+*~!@$%^&=/|<>'" cls plus

stringChar : Regex
stringChar = "\t !#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]^_`abcdefghijklmnopqrstuvwxyz{|}~" cls "\\" lit "ntr\\\"" cls seq2 alt2

stringRegex : Regex
stringRegex = "\"" lit stringChar star "\"" lit seq3

multistringChar : Regex
multistringChar = stringChar "\n" lit alt2

multistringAtom : Regex
multistringAtom = multistringChar "\"" lit multistringChar "\"" lit multistringChar seq2 alt2 seq2 alt2

multistringRegex : Regex
multistringRegex = "\"\"\"" lit multistringAtom star "\"\"\"" lit seq3

visibleChar : Regex
visibleChar = "\t !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~" cls

commentRegex : Regex
commentRegex = "#" lit visibleChar star seq2

trimRegex : Regex
trimRegex = " \t" cls star

newlineRegex : Regex
newlineRegex = commentRegex "\r\n" cls trimRegex seq2 alt2 plus


#
#
#

data LexerRule
  lexerRule(f: Str -- Token) : Regex -- LexerRule
end


lexerRules : List(LexerRule)
lexerRules = $(
  nil

  # literals
  "(" lit lexerRule(drop TLPAREN) cons
  ")" lit lexerRule(drop TRPAREN) cons
  "," lit lexerRule(drop TCOMMA) cons
  ":" lit lexerRule(drop TCOLON) cons

  # regexes
  decIntRegex lexerRule(readDecInt TINT) cons
  hexIntRegex lexerRule(readHexInt TINT) cons
  wordRegex   lexerRule(wordToken)       cons

  # newlines
  newlineRegex lexerRule(TNEWLINE) cons

  # strings
  stringRegex lexerRule(readString TSTR) cons
  multistringRegex lexerRule(readMultistring TSTR) cons
)

data LexerMatch
  lexerMatch(f: Str -- Token) : Maybe(Nat) -- LexerMatch
end

lexerMatchUnwrap : LexerMatch -- Maybe(Nat)
lexerMatchUnwrap = match( lexerMatch(f) -> id )

lexerMatchCmp? : LexerMatch LexerMatch -- LexerMatch LexerMatch Comp
lexerMatchCmp? = dup2 both(lexerMatchUnwrap) mcmp(ncmp)

lexerMatchOrder : Order(LexerMatch)
lexerMatchOrder = MkOrder(lexerMatchCmp?)

bestLexerMatch : Str -- LexerMatch
bestLexerMatch =
  lexerRules formap(
    match( lexerRule(f) ->
      dip(dup) regexMatch lexerMatch(f)
    )
  ) nip no_panic_11(maximum(lexerMatchOrder))

data LexerError
  lexerError : Loc Str -- LexerError
end

unLexerError : LexerError -- Loc Str
unLexerError = match( lexerError -> id )

lexerError->str : LexerError -- Str
lexerError->str = unLexerError dip(loc->str ":" <>) <>

trim : Loc Str -- Loc Str
trim = dup trimRegex regexMatch maybe(n0, id) strbreak dip(locNext)

tokenizeAux : List(LToken) Loc Str -- Result(LexerError, List(LToken))
tokenizeAux =
  trim cond(
    strnull? -> drop2 ok,
    dup bestLexerMatch match( lexerMatch(f) ->
      maybe(
        drop nip "Unrecognized token." lexerError err,
        strbreak dip(
          dip(dup) dup
          dip(locNext) f over
          dip(ltoken cons)
        ) tokenizeAux
      )
    )
  )

tokenize : Mod Str -- Result(LexerError, List(LToken))
tokenize = dip2(nil) dip(locStart) tokenizeAux

"10" tokenize
  == lambda(m -> nil m p1 p1 loc m p1 3 zpos loc 10 TINT ltoken cons ok)

"+42" tokenize
  == lambda(m -> nil m p1 p1 loc m p1 4 zpos loc +42 TINT ltoken cons ok)

"-5133" tokenize
  == lambda(m -> nil m p1 p1 loc m p1 6 zpos loc -5133 TINT ltoken cons ok)

"0" tokenize
  == lambda(m -> nil m p1 p1 loc m p1 2 zpos loc 0 TINT ltoken cons ok)

"0xFF" tokenize
  == lambda(m -> nil m p1 p1 loc m p1 5 zpos loc 255 TINT ltoken cons ok)

"  10" tokenize
  == lambda(m -> nil m p1 3 zpos loc m p1 5 zpos loc 10 TINT ltoken cons ok)

"" tokenize == drop nil ok
"      " tokenize == drop nil ok
"  \t     " tokenize == drop nil ok


"foobar" tokenize
  == lambda(m -> nil m p1 p1 loc m p1 7 zpos loc "foobar" TNAME ltoken cons ok)


